{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.026083781104908967,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005216756220981794,
      "grad_norm": 10.647161483764648,
      "learning_rate": 4.999217486566853e-05,
      "loss": 2.6011,
      "step": 10
    },
    {
      "epoch": 0.0010433512441963588,
      "grad_norm": 1.8372505903244019,
      "learning_rate": 4.9983480271966896e-05,
      "loss": 0.573,
      "step": 20
    },
    {
      "epoch": 0.001565026866294538,
      "grad_norm": 2.321108818054199,
      "learning_rate": 4.997478567826526e-05,
      "loss": 0.5704,
      "step": 30
    },
    {
      "epoch": 0.0020867024883927175,
      "grad_norm": 2.4985411167144775,
      "learning_rate": 4.996609108456362e-05,
      "loss": 0.4724,
      "step": 40
    },
    {
      "epoch": 0.0026083781104908966,
      "grad_norm": 2.3203821182250977,
      "learning_rate": 4.995739649086198e-05,
      "loss": 0.4788,
      "step": 50
    },
    {
      "epoch": 0.003130053732589076,
      "grad_norm": 2.7166740894317627,
      "learning_rate": 4.994870189716035e-05,
      "loss": 0.5174,
      "step": 60
    },
    {
      "epoch": 0.0036517293546872555,
      "grad_norm": 2.3354430198669434,
      "learning_rate": 4.9940007303458714e-05,
      "loss": 0.5301,
      "step": 70
    },
    {
      "epoch": 0.004173404976785435,
      "grad_norm": 1.9628956317901611,
      "learning_rate": 4.9931312709757076e-05,
      "loss": 0.5906,
      "step": 80
    },
    {
      "epoch": 0.0046950805988836145,
      "grad_norm": 1.8473578691482544,
      "learning_rate": 4.9922618116055445e-05,
      "loss": 0.513,
      "step": 90
    },
    {
      "epoch": 0.005216756220981793,
      "grad_norm": 1.7939976453781128,
      "learning_rate": 4.99139235223538e-05,
      "loss": 0.4765,
      "step": 100
    },
    {
      "epoch": 0.005738431843079973,
      "grad_norm": 2.3992502689361572,
      "learning_rate": 4.990522892865216e-05,
      "loss": 0.5036,
      "step": 110
    },
    {
      "epoch": 0.006260107465178152,
      "grad_norm": 2.558433771133423,
      "learning_rate": 4.989653433495053e-05,
      "loss": 0.5073,
      "step": 120
    },
    {
      "epoch": 0.0067817830872763316,
      "grad_norm": 2.1566410064697266,
      "learning_rate": 4.988783974124889e-05,
      "loss": 0.5376,
      "step": 130
    },
    {
      "epoch": 0.007303458709374511,
      "grad_norm": 2.03348708152771,
      "learning_rate": 4.9879145147547256e-05,
      "loss": 0.4852,
      "step": 140
    },
    {
      "epoch": 0.00782513433147269,
      "grad_norm": 2.1809980869293213,
      "learning_rate": 4.9870450553845625e-05,
      "loss": 0.542,
      "step": 150
    },
    {
      "epoch": 0.00834680995357087,
      "grad_norm": 2.191396713256836,
      "learning_rate": 4.986175596014399e-05,
      "loss": 0.5159,
      "step": 160
    },
    {
      "epoch": 0.00886848557566905,
      "grad_norm": 2.0715882778167725,
      "learning_rate": 4.985306136644235e-05,
      "loss": 0.5925,
      "step": 170
    },
    {
      "epoch": 0.009390161197767229,
      "grad_norm": 1.8855259418487549,
      "learning_rate": 4.984436677274071e-05,
      "loss": 0.4852,
      "step": 180
    },
    {
      "epoch": 0.009911836819865408,
      "grad_norm": 5.23197078704834,
      "learning_rate": 4.983567217903908e-05,
      "loss": 0.4965,
      "step": 190
    },
    {
      "epoch": 0.010433512441963586,
      "grad_norm": 1.6950998306274414,
      "learning_rate": 4.982697758533744e-05,
      "loss": 0.4484,
      "step": 200
    },
    {
      "epoch": 0.010955188064061766,
      "grad_norm": 1.8605097532272339,
      "learning_rate": 4.98182829916358e-05,
      "loss": 0.5511,
      "step": 210
    },
    {
      "epoch": 0.011476863686159945,
      "grad_norm": 2.4572927951812744,
      "learning_rate": 4.9809588397934166e-05,
      "loss": 0.4591,
      "step": 220
    },
    {
      "epoch": 0.011998539308258125,
      "grad_norm": 2.9382646083831787,
      "learning_rate": 4.980089380423253e-05,
      "loss": 0.5495,
      "step": 230
    },
    {
      "epoch": 0.012520214930356304,
      "grad_norm": 1.9297195672988892,
      "learning_rate": 4.979219921053089e-05,
      "loss": 0.5205,
      "step": 240
    },
    {
      "epoch": 0.013041890552454484,
      "grad_norm": 1.766375184059143,
      "learning_rate": 4.978350461682926e-05,
      "loss": 0.5561,
      "step": 250
    },
    {
      "epoch": 0.013563566174552663,
      "grad_norm": 1.3511799573898315,
      "learning_rate": 4.977481002312762e-05,
      "loss": 0.4904,
      "step": 260
    },
    {
      "epoch": 0.014085241796650843,
      "grad_norm": 1.2660772800445557,
      "learning_rate": 4.9766115429425984e-05,
      "loss": 0.4861,
      "step": 270
    },
    {
      "epoch": 0.014606917418749022,
      "grad_norm": 1.6579080820083618,
      "learning_rate": 4.975742083572435e-05,
      "loss": 0.5489,
      "step": 280
    },
    {
      "epoch": 0.015128593040847202,
      "grad_norm": 1.6379419565200806,
      "learning_rate": 4.9748726242022715e-05,
      "loss": 0.5012,
      "step": 290
    },
    {
      "epoch": 0.01565026866294538,
      "grad_norm": 2.025653600692749,
      "learning_rate": 4.974003164832108e-05,
      "loss": 0.5558,
      "step": 300
    },
    {
      "epoch": 0.01617194428504356,
      "grad_norm": 1.6355810165405273,
      "learning_rate": 4.973133705461944e-05,
      "loss": 0.5364,
      "step": 310
    },
    {
      "epoch": 0.01669361990714174,
      "grad_norm": 1.2127258777618408,
      "learning_rate": 4.97226424609178e-05,
      "loss": 0.4701,
      "step": 320
    },
    {
      "epoch": 0.017215295529239918,
      "grad_norm": 1.8024307489395142,
      "learning_rate": 4.9713947867216164e-05,
      "loss": 0.5085,
      "step": 330
    },
    {
      "epoch": 0.0177369711513381,
      "grad_norm": 1.4845383167266846,
      "learning_rate": 4.9705253273514526e-05,
      "loss": 0.5403,
      "step": 340
    },
    {
      "epoch": 0.018258646773436277,
      "grad_norm": 1.3614914417266846,
      "learning_rate": 4.9696558679812895e-05,
      "loss": 0.5168,
      "step": 350
    },
    {
      "epoch": 0.018780322395534458,
      "grad_norm": 1.4015623331069946,
      "learning_rate": 4.968786408611126e-05,
      "loss": 0.4683,
      "step": 360
    },
    {
      "epoch": 0.019301998017632636,
      "grad_norm": 1.2748990058898926,
      "learning_rate": 4.967916949240962e-05,
      "loss": 0.4395,
      "step": 370
    },
    {
      "epoch": 0.019823673639730817,
      "grad_norm": 3.8571128845214844,
      "learning_rate": 4.967047489870799e-05,
      "loss": 0.5188,
      "step": 380
    },
    {
      "epoch": 0.020345349261828995,
      "grad_norm": 2.487579345703125,
      "learning_rate": 4.966178030500635e-05,
      "loss": 0.517,
      "step": 390
    },
    {
      "epoch": 0.020867024883927172,
      "grad_norm": 1.2822864055633545,
      "learning_rate": 4.965308571130471e-05,
      "loss": 0.4659,
      "step": 400
    },
    {
      "epoch": 0.021388700506025354,
      "grad_norm": 1.466988205909729,
      "learning_rate": 4.964439111760308e-05,
      "loss": 0.5373,
      "step": 410
    },
    {
      "epoch": 0.02191037612812353,
      "grad_norm": 1.134255051612854,
      "learning_rate": 4.9635696523901444e-05,
      "loss": 0.5066,
      "step": 420
    },
    {
      "epoch": 0.022432051750221713,
      "grad_norm": 1.3682496547698975,
      "learning_rate": 4.9627001930199806e-05,
      "loss": 0.4879,
      "step": 430
    },
    {
      "epoch": 0.02295372737231989,
      "grad_norm": 1.1425812244415283,
      "learning_rate": 4.961830733649817e-05,
      "loss": 0.4527,
      "step": 440
    },
    {
      "epoch": 0.02347540299441807,
      "grad_norm": 1.1155552864074707,
      "learning_rate": 4.960961274279653e-05,
      "loss": 0.5529,
      "step": 450
    },
    {
      "epoch": 0.02399707861651625,
      "grad_norm": 1.5979855060577393,
      "learning_rate": 4.960091814909489e-05,
      "loss": 0.5408,
      "step": 460
    },
    {
      "epoch": 0.02451875423861443,
      "grad_norm": 2.5195536613464355,
      "learning_rate": 4.9592223555393255e-05,
      "loss": 0.478,
      "step": 470
    },
    {
      "epoch": 0.02504042986071261,
      "grad_norm": 1.3785332441329956,
      "learning_rate": 4.9583528961691624e-05,
      "loss": 0.5365,
      "step": 480
    },
    {
      "epoch": 0.02556210548281079,
      "grad_norm": 0.9923838376998901,
      "learning_rate": 4.9574834367989986e-05,
      "loss": 0.4934,
      "step": 490
    },
    {
      "epoch": 0.026083781104908967,
      "grad_norm": 0.9477042555809021,
      "learning_rate": 4.956613977428835e-05,
      "loss": 0.4025,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 57507,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 65324187648000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
